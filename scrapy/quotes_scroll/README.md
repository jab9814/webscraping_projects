# Proyecto Scrapy quotes scroll

âœ¨ğŸ“ [Quotes](https://quotes.toscrape.com/scroll)  es el sitio web con citas populares de diferentes autores sobre diversos temas. Â¿A quiÃ©n no le gusta escuchar citas? A todos nos gusta escucharlas porque nos permiten conectar con sentimientos como el miedo, la tristeza, la motivaciÃ³n, la ciencia, el arte, entre otras...

ğ“‡¼ Mediante el uso del framework Scrapy en el siguiente proyecto, se realizara lo siguiente:

- Obtener informaciÃ³n mediante Scrapy en una pÃ¡gina con un scroll indefinido. Dicha pagina cuenta con una API con las citas y redirigir hacia otra pÃ¡gina con sus correspondientes autores.
- La extracciÃ³n de la citas que se encuentran en la pagina [Quotes](https://quotes.toscrape.com/scroll), como tambiÃ©n la informaciÃ³n de los autores desde la pagina [Good Reads](https://www.goodreads.com/), en un formato json
- ManipulaciÃ³n, limpieza y transformaciÃ³n del formato json mediante el uso de la librerÃ­a [Pandas](https://pandas.pydata.org/) para obtener la informaciÃ³n necesaria a un archivo csv para sus correspondientes anÃ¡lisis o carga de datos a una DB

## Indice

- [Proyecto Scrapy quotes scroll](#proyecto-scrapy-quotes-scroll)
- [Estructura del proyecto](#estructura-del-proyecto)
- [Comando de ejecuciÃ³n de la araÃ±a](#comando-de-ejecucion-de-la-araÃ±a)
- [Ejemplo de la informaciÃ³n extraÃ­da](#ejemplo-de-la-informaciÃ³n-extraÃ­da)

## Estructura del proyecto

```bash
.
â”œâ”€â”€ README.md
â”œâ”€â”€ data                            # Se crea una vez ejecutada la arana
â”‚Â Â  â”œâ”€â”€ quotes_scroll.json          # Se crea una vez se realiza la extracciÃ³n
â”‚Â Â  â””â”€â”€ quotes_scroll_refine.csv    # Se crea una vez se realiza el refinado
â”œâ”€â”€ quotes_scroll
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ data_refactory.py
â”‚Â Â  â”œâ”€â”€ enum_models.py
â”‚Â Â  â”œâ”€â”€ items.py
â”‚Â Â  â”œâ”€â”€ middlewares.py
â”‚Â Â  â”œâ”€â”€ pipelines.py
â”‚Â Â  â”œâ”€â”€ settings.py
â”‚Â Â  â””â”€â”€ spiders
â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â””â”€â”€ quotes_scroll_spider.py
â””â”€â”€ scrapy.cfg
```

## Modificaciones realizadas al proyecto Scrapy

En la siguiente lista se pueden observar los mÃ³dulos a los cuales se les realizÃ³ modificaciones al proyecto creado con startproject

- [settings](quotes_scroll/settings.py):
    - Habilitar cantidad de reintentos y para ciertos cÃ³digos de respuesta HTTP
    - Tiempos de ejecuciÃ³n y peticiones a la pagina, con el fin de hacerlo dinÃ¡mico y aleatorio, para evitar posibles bloqueos
- [items](quotes_scroll/items.py):
    - Agregados nuevos campos al model de extracciÃ³n
- [enum_models](quotes_scroll/enum_models.py)
    - Configuracion del archivo formato json como del archivo csv
- [pipelines](quotes_scroll/pipelines.py)
    - Control de procesos desde el inicio de la araÃ±a hasta finalizar su extracciÃ³n
    - Indicaciones al proceso cuando debe realizarse una extracciÃ³n y/o refinar la data extraÃ­da.
    - Uso de la metodologÃ­a Refactory para la manipulaciÃ³n, transformaciÃ³n y limpieza de los datos extraÃ­dos
- [data_refactory](quotes_scroll/data_refactory.py)
    - MetodologÃ­a refactory para los procesos ETL de la data obtenida
- [quotes_scroll_spider](quotes_scroll/spiders/quotes_spider.py)
    - Mediante el mÃ©todo from_crawler de la clase principal de la araÃ±a, se utiliza para indicar cuando no es necesario crear o sobrescribir el archivo json de extracciÃ³n

## Comando de ejecucion de la araÃ±a

ğŸ•·ï¸ Para la ejecuciÃ³n de la araÃ±a es necesario contar con el entorno virtual activado (nota: revisar los [requirements](/scrapy/requirements.txt) necesarios).

Dentro del proyecto, se define un parÃ¡metro externo denominado **refine**. Dicho parÃ¡metro ronda en los siguientes valores:

```bash
refine = 0  # Extraccion de las citas y los autores en el formato json
refine = 1  # Refinado de las citas y los autores para la creacion del archivo csv
refine = 2  # Extraccion del archivo json y refinado para la creaccion del archivo csv
```

Para ejecutar la araÃ±a se tiene los siguientes comandos, segÃºn sea la conveniencia. Nota: Es necesario encontrarse dentro del proyecto [quotes_scroll](/scrapy/quotes_scroll/), para su correcta ejecuciÃ³n.

```bash
scrapy crawl quotes_scroll_spider -a refine = 0
scrapy crawl quotes_scroll_spider -a refine = 1
scrapy crawl quotes_scroll_spider -a refine = 2
```

Por defecto el parÃ¡metro refine es igual a 2; por lo que, se puede tambiÃ©n ejecutar el comando:

```bash
scrapy crawl quotes_scroll_spider
```

Una vez ejecutada la araÃ±a y finalizado el proceso de extracciÃ³n y refinado, se crearÃ¡ una carpeta en la siguiente ruta [data](data/), donde contarÃ¡ con:

- Un archivo json con las citas extraÃ­das e informaciÃ³n del autor
- Un archivo csv con las citas e informaciÃ³n del autor con su respectiva limpieza y transformaciÃ³n de datos

## Ejemplo de la informaciÃ³n extraÃ­da

Desde la pagina se observa la extracciÃ³n, en formato .json, la siguiente cita:

InformaciÃ³n de la autora [Jane_Austen](https://www.goodreads.com/author/show/1265.Jane_Austen)

``` json
{
    "quotes_author_name": "Jane Austen",
    "quotes_author_slug": "Jane-Austen",
    "quotes_author_goodreads_link": "https://www.goodreads.com/author/show/1265.Jane_Austen",
    "quotes_tags": [
        "elizabeth-bennet",
        "jane-austen"
    ],
    "quotes_text": "â€œThere are few people whom I really love, and still fewer of whom I think well. The more I see of the world, the more am I dissatisfied with it; and every day confirms my belief of the inconsistency of all human characters, and of the little dependence that can be placed on the appearance of merit or sense.â€",
    "goodreads_name": "Jane Austen",
    "goodreads_born_date": "December 16, 1775",
    "goodreads_death_date": "July 18, 1817",
    "goodreads_born_location": "in Steventon Rectory, Hampshire, England",
    "goodreads_description": "Jane Austen was an English novelist known primarily for her six novels, which implicitly interpret, critique, and comment upon the English landed gentry at the end of the 18th century... "
},
...
```
